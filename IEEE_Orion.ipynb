{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IEEE_Orion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjvvp+592wrOzfGtzPDuFN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pahsantana/App_web_ASP_dotnet_MVC/blob/master/IEEE_Orion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhpvvUYUnHs"
      },
      "source": [
        "#Libraries\n",
        "import numpy as np # Library used for working with arrays. It also has functions for working in domain of linear algebra\n",
        "import pandas as pd # Library used for data structures and data analysis tools\n",
        "import matplotlib.pyplot as plt #Comprehensive library for creating static, animated, and interactive visualizations \n",
        "from PIL import Image # Biblioteca para manipular as imgs (fazer a leitura, plotar, etc)\n",
        "from glob import glob # Módulo para encontrar arquivos dado um diretório\n",
        "#import cv2  \n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0aC4j8dkPoq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWVTj2hAU0Wk"
      },
      "source": [
        "data_dir = './CrackForest-dataset-master.zip/CrackForest-dataset-master/image' # Acessar o diretório com as imagens\n",
        "image_files = glob(data_dir + '/*.jpg') # Criar um dataset com todos os diretórios das imgs\n",
        "\n",
        "data_dir_asphalt_crack = './Asphalt Crack Dataset.zip/Asphalt Crack Dataset/448/Cracks' # Acessar o diretório com as imagens\n",
        "asphalt_crack_files = glob(data_dir_asphalt_crack + '/*.jpg') # Criar um dataset com todos os diretórios das imgs\n",
        "\n",
        "data_dir_asphalt_noncrack = '/Asphalt Crack Dataset.zip/Asphalt Crack Dataset/448/NonCracks' # Acessar o diretórbio com as imagens\n",
        "asphalt_noncrack_files = glob(data_dir_asphalt_noncrack + '/*.jpg') # Criar um dataset com todos os diretórios das imgs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6spY1ddZbd0A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0cb06d63-0930-4034-8899-8984350edd42"
      },
      "source": [
        "image_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLlKiZS4Vn8M"
      },
      "source": [
        "# A função abaixo vai criar 2 datasets contendo os pixels de cada imagem contida no dataset dos Diretórios   \n",
        "# O primeiro dataset contém as imgs originais, o segundo contém as imgs rotacionadas em 180°\n",
        "# E no final vai nos retornar um dataset que junta os dois anteriores, dessa forma consigo\n",
        "# duplicar meu número de dados\n",
        "\n",
        "def df_create_2(df_name, df_name_rotate, image_data): # (dataframe1 vazio, dataframe1 rotacionado vazio, dataset do diretório)    \n",
        "    for file in range(0, len(image_data),1): # com esse for vamos varrer cada linha do meu dataset com os dir\n",
        "        img1 = Image.open(image_data[file],'r') # Estamos lendo as imgs do dataset que contém os dirs\n",
        "        img1 = img1.convert('L') # Transformando a img para greyscale\n",
        "        img1 = img1.resize((28, 28)) \n",
        "        img1_rotate = img1.rotate(180) # Rotacionando a img em 180°\n",
        "        \n",
        "        img1_n = np.asarray(img1.getdata(), dtype=np.float64) # Convertendo a img para pixels e salvando em um Numpy Array de 1 dimensão   \n",
        "        img1_n_rotate = np.asarray(img1_rotate.getdata(), dtype=np.float64) # Fazendo a mesma coisa para a imagem rotacionada\n",
        "        \n",
        "        df_name[file] = img1_n # Adicionando os pixels de uma img no dataframe1 vazio\n",
        "        df_name_rotate[file] = img1_n_rotate # Mesma coisa para as imgs rotacionadas\n",
        "        \n",
        "    df_name = df_name.T # Pegando a transposta da Matrix para que as linhas sejam as imagens e as colunas seus pixels\n",
        "    df_name_rotate = df_name_rotate.T # Pegando a transposta da Matrix para que as linhas sejam as imagens e as colunas seus pixel\n",
        "    df_concat = pd.concat([df_name,df_name_rotate], ignore_index=True) # Juntando as duas matrizes \n",
        "    return df_concat # Retornando o DataFrame(Matriz) Desejada"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmIpRdoYV--r"
      },
      "source": [
        "# A função abaixo faz a mesma coisa que a df_create_2, porém ela triplica o meu número de imagem\n",
        "# Ou seja, ela criar três dataframes(matrizes), o primeiro sendo as imgs originais\n",
        "# O segundo as imgs rotacionadas em 90° e o terceiro as imgs rotacionadas em 180°\n",
        "def df_create_3(df_name, df_name_rotate90,df_name_rotate180, image_data):\n",
        "    #df_name = pd.DataFrame()\n",
        "    for file in range(0, len(image_data),1):\n",
        "        img1 = Image.open(image_data[file],'r')\n",
        "        img1 = img1.convert('L') # Makes it greyscale\n",
        "        img1 = img1.resize((448, 448))\n",
        "        img1_rotate90 = img1.rotate(90)\n",
        "        img1_rotate180 = img1.rotate(180)\n",
        "        \n",
        "        img1_n = np.asarray(img1.getdata(), dtype=np.float64)\n",
        "        img1_n_rotate90 = np.asarray(img1_rotate90.getdata(), dtype=np.float64)\n",
        "        img1_n_rotate180 = np.asarray(img1_rotate180.getdata(), dtype=np.float64)\n",
        "\n",
        "        df_name[file] = img1_n\n",
        "        df_name_rotate90[file] = img1_n_rotate90\n",
        "        df_name_rotate180[file] = img1_n_rotate180\n",
        "        \n",
        "    df_name = df_name.T\n",
        "    df_name_rotate90 = df_name_rotate90.T\n",
        "    df_name_rotate180 = df_name_rotate180.T\n",
        "    df_concat = pd.concat([pd.concat([df_name,df_name_rotate90], ignore_index=True),df_name_rotate180], ignore_index=True)   \n",
        "    #df_concat = df_concat.reset_index().drop('index', axis=1)\n",
        "    return df_concat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqdpOnL3WAag"
      },
      "source": [
        "# DataFrame 1 com imagens de rachaduras, utilizando a função df_create_2\n",
        "df_crack1 = pd.DataFrame()\n",
        "df_crack1_rotate = pd.DataFrame()\n",
        "df_crack1 = df_create_2(df_crack1, df_crack1_rotate, image_files)\n",
        "\n",
        "# Dataframe 2 com imagens de rachadura, utilizando a função df_create_2\n",
        "df_crack2 = pd.DataFrame()\n",
        "df_crack2_rotate = pd.DataFrame()\n",
        "df_crack2 = df_create_2(df_crack2, df_crack2_rotate, asphalt_crack_files)\n",
        "\n",
        "# Dataframe 3 combinando os Dataframes 1 e 2, totalizando 710 imagens de rachaduras\n",
        "df_crack = pd.concat([df_crack1, df_crack2], ignore_index=True)\n",
        "\n",
        "# Dataframe com imagens sem rachaduras\n",
        "# Aqui eu chamo a função df_create_3 e triplico o número de dados que tenho de imgs sem rachaduras \n",
        "df_non_crack = pd.DataFrame()\n",
        "df_non_crack_rotate90 = pd.DataFrame()\n",
        "df_non_crack_rotate180 = pd.DataFrame()\n",
        "df_non_crack = df_create_3(df_non_crack, df_non_crack_rotate90, df_non_crack_rotate180, asphalt_noncrack_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoWNidvoWG6P"
      },
      "source": [
        "\n",
        "**Visualização dos DataFrames**\n",
        "\n",
        "* Dataframe com as imagens de rachaduras no solo\n",
        "* Total de 710 imagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mawOiX6-WbZa"
      },
      "source": [
        "# Criando a coluna label (target value)\n",
        "#df_crack.to_csv('df_crack.csv', index=False)\n",
        "df_crack['label'] = 1\n",
        "df_crack.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTYK1ZekWhlM"
      },
      "source": [
        "\n",
        "*   Dataframe com as imagens sem rachaduras\n",
        "*   Total de 600 imagens"
      ]
    }
  ]
}